% Copyright 2004 by Till Tantau <tantau@users.sourceforge.net>.
%
% In principle, this file can be redistributed and/or modified under
% the terms of the GNU Public License, version 2.
%
% However, this file is supposed to be a template to be modified
% for your own needs. For this reason, if you use this file as a
% template and not specifically distribute it as part of a another
% package/program, I grant the extra permission to freely copy and
% modify this file as you see fit and even to delete this copyright
% notice. 

\documentclass[aspectratio=169]{beamer}
%\documentclass{beamer}

\setbeamersize{text margin left=10mm, text margin right=10mm}
% \setbeamersize{text margin left=2mm, text margin right=2mm}

\defbeamertemplate{headline}{my header}{%
\vskip1pt%
\makebox[0pt][l]{\,\insertshortauthor}%
\hspace*{\fill}\insertshorttitle/\insertshortsubtitle\hspace*{\fill}%
\llap{\insertpagenumber/\insertpresentationendpage\,}
}
\setbeamertemplate{headline}[my header]


\usepackage{soul}
\usepackage{tkz-euclide}
\usetikzlibrary{calc}
\usepackage[]{algorithm2e}
\usepackage{changepage}
\usepackage{amssymb}
\usepackage{xcolor}
\usepackage{mathtools}
\usepackage{tcolorbox}
\usepackage{tikz}
\usepackage{tikz-3dplot}
\usepackage{tkz-euclide}
\usepackage{circuitikz}
\usepackage{mleftright}
% \usepackage[math]{cellspace}
% \cellspacetoplimit 4pt
% \cellspacebottomlimit 4pt
%\usetikzlibrary{arrows.meta}



%\setbeamertemplate{itemize items}{-}

%\usepackage{helvet}
\usefonttheme{professionalfonts} % using non standard fonts for beamer
%\usefonttheme{serif} % default family is serif
%\usepackage{fontspec}
%\setmainfont{Liberation Serif}

% There are many different themes available for Beamer. A comprehensive
% list with examples is given here:
% http://deic.uab.es/~iblanes/beamer_gallery/index_by_theme.html
% You can uncomment the themes below if you would like to use a different
% one:
%\usetheme{AnnArbor}
%\usetheme{Antibes}
%\usetheme{Bergen}
%\usetheme{Berkeley}
%\usetheme{Berlin}
%\usetheme{Boadilla}
%\usetheme{boxes}
%\usetheme{CambridgeUS}
%\usetheme{Copenhagen}
%\usetheme{Darmstadt}
%\usetheme{default}
%\usetheme{Frankfurt}
%\usetheme{Goettingen}
%\usetheme{Hannover}
%\usetheme{Ilmenau}
%\usetheme{JuanLesPins}
%\usetheme{Luebeck}
%\usetheme{Madrid}
%\usetheme{Malmoe}
%\usetheme{Marburg}
%\usetheme{Montpellier}
%\usetheme{PaloAlto}
%\usetheme{Pittsburgh}
%\usetheme{Rochester}
%\usetheme{Singapore}
%\usetheme{Szeged}
%\usetheme{Warsaw}

\def\mf{\ensuremath\mathbf}
\def\mb{\ensuremath\mathbb}
\def\mc{\ensuremath\mathcal}
\def\lp{\ensuremath\left(}
\def\rp{\ensuremath\right)}
\def\lv{\ensuremath\left\lvert}
\def\rv{\ensuremath\right\rvert}
\def\lV{\ensuremath\left\lVert}
\def\rV{\ensuremath\right\rVert}
\def\lc{\ensuremath\left\{}
\def\rc{\ensuremath\right\}}
\def\bmx{\ensuremath\begin{bmatrix*}[r]}
\def\emx{\ensuremath\end{bmatrix*}}

\newcommand{\demoex}[2]{\onslide<#1->\begin{color}{black!60} #2 \end{color}}
\newcommand{\anim}[3]{\onslide<#1->{\begin{color}{#2!60} #3 \end{color}}}


\title{Linear Systems}

% A subtitle is optional and this may be deleted
\subtitle{Orthogonality}

\author{Sivakumar Balasubramanian}
% - Give the names in the same order as the appear in the paper.
% - Use the \inst{?} command only if the authors have different
%   affiliation.

\institute[Christian Medical College] % (optional, but mostly needed)
{
  \inst{}%
  Department of Bioengineering\\
  Christian Medical College, Bagayam\\
  Vellore 632002
}
% - Use the \inst command only if there are several affiliations.
% - Keep it simple, no one is interested in your street address.

\date{}
% - Either use conference name or its abbreviation.
% - Not really informative to the audience, more for people (including
%   yourself) who are reading the slides online

\subject{Lecture notes on linear systems}
% This is only inserted into the PDF information catalog. Can be left
% out. 

% If you have a file called "university-logo-filename.xxx", where xxx
% is a graphic format that can be processed by latex or pdflatex,
% resp., then you can add a logo as follows:

% \pgfdeclareimage[height=0.5cm]{university-logo}{university-logo-filename}
% \logo{\pgfuseimage{university-logo}}

% Delete this, if you do not want the table of contents to pop up at
% the beginning of each subsection:
\AtBeginSubsection[]
{
  \begin{frame}<beamer>{Outline}
    \tableofcontents[currentsection,currentsubsection]
  \end{frame}
}

% Let's get started
\begin{document}

\begin{frame}
  \titlepage
\end{frame}

\begin{frame}[t]{References}
\begin{itemize}
    \item S Boyd, Applied Linear Algebra: Chapters 5.
    \item G Strang, Linear Algebra: Chapters 3.
\end{itemize}
\end{frame}


\begin{frame}[t]{Orthogonality}
\vspace{-0.25cm}
\begin{itemize}
\item Two vectors $\mf{x}, \mf{y} \in \mb{R}^n$ are orthognal if $\mf{x}^T\mf{y} = 0$.
\begin{center}
\begin{tikzpicture}[scale=0.75]
  \draw[black,thick,->] (0, 0) -- (2, 2) node[black, above, right]{$\mf{x}$};
  \draw[black,thick,->] (0, 0) -- (-1, 1) node[black, above, left]{$\mf{y}$};
  \draw [gray,thin](0.2,0.2) -- (0, 0.4) -- (-0.2, 0.2);
\end{tikzpicture}
\end{center}

\item If we have a set of non-zero vectors $\mc{V} = \left\{\mf{v}_1, \mf{v}_2, \mf{v}_3, \ldots, \mf{v}_r\right\}$, we say this a set of mutually orthogonal vectors, if and only if, $\mf{v}_i^T\mf{v}_j = 0, \,\,\, 1 \leq i, j \leq r \text{ and } i \neq j$.

$\mc{V}$ is also a linearly independent set of vectors.

\item When the length of the vectors is $1$, it is called an \textbf{orthonormal} set of vectors.

\item A set of orthonormal vectors $V$ also form an \textbf{orthonormal basis} of the subsapce $span \left(\mc{V}\right)$.

\end{itemize}

\demoex{2}{
Is $\left\{\begin{bmatrix*}[r]1\\-2\\4\end{bmatrix*}, \begin{bmatrix*}[r]-2\\1\\1\end{bmatrix*}\right\}$ an orthonormal set?. If no, how will you make it one?
}

\end{frame}


\begin{frame}[t]{Orthogonal Subspaces}
\vspace{-0.25cm}
\begin{itemize}
\item Two subspaces $\mc{V}, \mc{W}$ are orthogonal if every vector in one subspace is orthogonal to every vector in the other subspace.
\[ \mf{v}^T\mf{w} = 0, \,\,\, \forall \mf{v} \in \mc{V} \text{ and } \forall\mf{w} \in \mc{W} \]
Both subspaces $\mc{V}, \mc{W}$ are from the same space, e.g. $\mb{R}^n$

\item Consider two subspaces $\mc{V}, \mc{W} \subset \mb{R}^n$, such that $\mc{V} + \mc{W} = \mb{R}^n$. If $\mc{V}$ and $\mc{W}$ are orthogonal subspaces, then $\mc{V}$ and $\mc{W}$ are \textbf{orthogonal complements} of each other.
\[ \mc{W} \perp \mc{V}\,\,\, \rightarrow \,\,\, \mc{V}^{\perp} = \mc{W} \text{ or } \mc{W}^{\perp} = \mc{V}; \,\,\,\,\, \left(\mc{V}^{\perp}\right)^{\perp} = \mc{V} \]
\end{itemize}

\begin{small}
\demoex{2}{
$\mc{V} = span \left\{\begin{bmatrix*}[r]1\\1\\1\end{bmatrix*}^T, \begin{bmatrix*}[r]1\\0\\-1\end{bmatrix*}^T\right\}$ and $\mc{W} = span \left\{\begin{bmatrix*}[r]1\\-2\\1\end{bmatrix*}^T\right\}$. Is $\mc{V}^\perp = \mc{W}$? If we add $\begin{bmatrix*}[r]1\\-1\\0\end{bmatrix*}^T$ to $\mc{W}$, is $\mc{V}^\perp = \mc{W}$ still true?
}
\end{small}
\end{frame}


\begin{frame}[t]{Relationship between the Four Fundamental Spaces}
% \vspace{-0.1cm}
\begin{columns}
\begin{column}{0.475\textwidth}
\begin{small}
\begin{itemize}
    \item $\mc{C}\lp\mf{A}\rp, \mc{N}\lp\mf{A}^T\rp \subseteq \mb{R}^m$ are orthogonal complements.
    $$\mc{C}\lp\mf{A}\rp \perp \mc{N}\lp\mf{A}^T\rp$$

    \item $\mc{C}\lp\mf{A}^T\rp, \mc{N}\lp\mf{A}\rp \subseteq \mb{R}^n$ are orthogonal complements.
    $$\mc{C}\lp\mf{A}^T\rp \perp \mc{N}\lp\mf{A}\rp$$
    
    \item $\dim \mc{C}\lp\mf{A}\rp + \dim \mc{N}\lp\mf{A}^T\rp = m \implies \mc{C}\lp\mf{A}\rp + \mc{N}\lp\mf{A}^T\rp = \mb{R}^m$
    
    \item $\dim \mc{C}\lp\mf{A}^T\rp + \dim \mc{N}\left(\mf{A}\rp = n \implies \mc{C}\lp\mf{A}^T\rp + \mc{N}\lp\mf{A}\rp = \mb{R}^n$
\end{itemize}
\end{small}
\end{column}
\begin{column}{0.525\textwidth}
\demoex{2}{
\begin{scriptsize}
\[ \mf{A} = \begin{bmatrix*}[r]
1 & -2 & 1 & 0 & 1 \\
2 & -4 & 1 & -1 & -2 \\
-1 & 2 & 1 & 1 & 2 \\
2 & -4 & -2 & -2 & -4 \\
\end{bmatrix*} \]

\[ \mf{E} = \begin{bmatrix*}[r]\mf{E}_1\\\mf{E}_2\end{bmatrix*} = \mleft[
\begin{array}{r r r r}
1 & 0 & 0 & 0 \\
-2 & 1 & 0 & 0 \\
-3 & 2 & 1 & 0 \\
\hline
0 & 0 & 2 & 1 \\
\end{array} \mright] \]

\[ \mf{R} = \begin{bmatrix*}[r]\mf{R}_1\\\mf{R}_2\end{bmatrix*} = \mleft[
\begin{array}{r r r r r} 
1 & -2 & 1 & 0 & 1 \\
0 & 0 & -1 & -1 & -4 \\
0 & 0 & 0 & -1 & -5 \\
\hline
0 & 0 & 0 & 0 & 0
\end{array}\mright] \]
\end{scriptsize}
}

\begin{color}{black!60}
\begin{footnotesize}
- Is $\mc{C}\lp\mf{A}\rp \perp \mc{N}\lp\mf{A}^T\rp$?

- Is $\mc{C}\lp\mf{A}^T\rp \perp \mc{N}\lp\mf{A}\rp$?

- What is $\dim \mc{C}\lp\mf{A}\rp$, $\dim \mc{N}\lp\mf{A}^T\rp$, $\dim \mc{C}\lp\mf{A}^T\rp$, $\dim \mc{N}\lp\mf{A}\rp$?
\end{footnotesize}
\end{color}
\end{column}
\end{columns}
\end{frame}


\begin{frame}[t]{Relationship between the Four Fundamental Spaces}
\vspace{-0.25cm}
\begin{columns}
\begin{column}{0.6\textwidth}
\begin{center}
\begin{circuitikz}[scale=0.6]
    \filldraw[fill=black] (0,0) circle (0.1cm);
    \draw[thick,rotate around={30:(0,0)}] (0,0) rectangle (3,4);
    \draw[thick,rotate around={30:(0,0)}] (0,0) rectangle (-1.5,-2);
    \node[yshift=0.1cm, xshift=-0.3cm] at (0, 0) {$\mf{0}$};
    \node[yshift=2.2cm] at (0, 0) {$\mc{C}\lp\mf{A}^T\rp$};
    \node[yshift=-1.9cm] at (0, 0) {$\mc{N}\lp\mf{A}\rp$};
    \draw[thick,rotate around={-30:(10,0)}] (10,0) rectangle (6,5);
    \draw[thick,rotate around={-30:(10,0)}] (10,0) rectangle (13,-3.75);
    \node[yshift=0.1cm, xshift=0.3cm] at (10, 0) {$\mf{0}$};
    \node[yshift=2.5cm] at (10, 0) {$\mc{C}\lp\mf{A}\rp$};
    \node[yshift=-1.9cm] at (10, 0) {$\mc{N}\lp\mf{A}^T\rp$};
    
    \draw[blue, thin, dashed] (-0.5, 3) to node[currarrow] {} (10,2);
    \draw[red, thin, dashed] (-0.5, 3) -- (1.9, 0.6);
    \filldraw[fill=black] (-0.5,3) circle (0.1cm);
    \node[yshift=-0.3cm] at (-0.5,3) {$\mf{x}_r$};
    \draw[blue, thin, dashed] (-0.2,-1.5) to node[currarrow] {} (10,0);
    \draw[red, thin, dashed] (-0.2,-1.5) -- (1.9, 0.6);
    \filldraw[fill=black] (-0.2,-1.5) circle (0.1cm);
    \node[yshift=-0.25cm] at (-0.2,-1.5) {$\mf{x}_n$};
    \filldraw[fill=black] (10,0) circle (0.1cm);

    \draw[blue, thin, dashed] (1.9,0.6) to node[currarrow] {} (10,2);
    \filldraw[fill=black] (1.9,0.6) circle (0.1cm);
    \node[right, yshift=-0.3cm] at (1.9,0.6) {$\mf{x} = \mf{x}_r + \mf{x}_n$};
    
    \filldraw[fill=black] (10,2) circle (0.1cm);
    \node[yshift=-0.3cm] at (10,2) {$\mf{b}$};
\end{circuitikz}
\end{center}
\end{column}

\begin{column}{0.4\textwidth}
\begin{footnotesize}
\begin{itemize}
    \item $\mf{x}_r$ and $\mf{x}_n$ are the components of $\mf{x} \in \mb{R}^n$ in the row space and nullspace of $\mf{A}$.
    \item \textbf{Nullspace} $\mc{N}\lp\mf{A}\rp$ is mapped to $\mf{0}$.
    \[ \mf{A}\mf{x}_n = \mf{0} \]
    \item \textbf{Row space} $\mc{C}\lp\mf{A}^T\rp$ is mapped to the \textbf{column space} $\mc{C}\lp\mf{A}\rp$.
    \[ \mf{A}\mf{x}_r = \mf{A}\lp\mf{x}_r + \mf{x}_n\rp = \mf{Ax} = \mf{b} \]
    \item The mapping from the \textbf{row space} to the \textbf{column space} is invertible, i.e. every $\mf{x}_r$ is mapped to a unique element in $\mc{C}\lp\mf{A}\rp$
    \item What sort of mapping does $\mf{A}^T$ do?
\end{itemize}
\end{footnotesize}
\end{column}
\end{columns}
\end{frame}


\begin{frame}[t]{Orthogonal Projection onto Subspaces}
\begin{columns}
\begin{column}{0.6\textwidth}
\vspace{-0.65cm}
\begin{center}
\begin{tikzpicture}[scale=0.6]
    \draw[gray, thin, ->] (-1, 0) -- (4, 0) node[right] {\footnotesize {$\mf{e_1}$}};
    \draw[gray, thin, ->] (0, -1) -- (0, 3) node[above] {\footnotesize {$\mf{e_2}$}};
    \draw[black, thick, ->] (0, 0) -- (4, 2) node[right, above] {\footnotesize {$\mf{a}$}};
    \draw[black, thick, ->] (0, 0) -- (1, 2) node[right, above] {\footnotesize {$\mf{b}$}};
    \draw[black, thick, ->] (0, 0) -- (1.6, 0.8) node[right, below] {\footnotesize{$\mf{p}$}};
    \draw[gray, thin, dashed] (1, 2) -- (1.6, 0.8) node[xshift=0.45cm, yshift=0.7cm, black] {{\footnotesize $\mf{e} = \mf{b - p}$}};
    \node[right, yshift=-0.5cm, black] at (0,0) {{\footnotesize $\mf{p}$ is the projection of $\mf{b}$ onto $\mf{a}$.}};
\end{tikzpicture}
\end{center}
\vspace{-0.2cm}
$\left\lVert \mf{e}\right\rVert$ is the distance of the point $\mf{b}$ from the line along $\mf{a}$. This distance is shortest when, $\mf{e} \perp \mf{a}$.
\[ \mf{a}^T\left(\mf{b} - \mf{p}\right) = \mf{a}^T\left(\mf{b} - \alpha \mf{a}\right) = \mf{a}^T\mf{b} - \alpha \mf{a}^T\mf{a} = 0 \]
\[ \alpha = \frac{\mf{a}^T\mf{b}}{\mf{a}^T\mf{a}} \implies \mf{p} = \frac{\mf{a}^T\mf{b}}{\mf{a}^T\mf{a}}\mf{a} \]
\[ \mf{p} = \frac{\mf{a}^T\mf{b}}{\mf{a}^T\mf{a}}\mf{a} =  \mf{a}\frac{\mf{a}^T\mf{b}}{\mf{a}^T\mf{a}} = \frac{\mf{a}\mf{a}^T}{\mf{a}^T\mf{a}}\mf{b} = \mf{Pb} \]
    % \item $\mf{P} = \frac{\mf{aa}^T}{\mf{a}^T\mf{a}}$ is the projection matricesx onto the line $\mf{a}$.
\end{column}
\begin{column}{0.4\textwidth}
$\mf{P} = \frac{\mf{aa}^T}{\mf{a}^T\mf{a}}$ is the projection matrix onto the line $\mf{a}$.

\vspace{0.25cm}

\demoex{2}{
\begin{small}
Find the orthogonal projection matrix associated $\mf{a}$, and find the projection of $\mf{b}$ on to $span \lp\left\{\mf{a}\right\}\rp$.\vspace{0.2cm}

$\bullet$ $\mf{a} = \begin{bmatrix*}[r]-1\\2\end{bmatrix*}$;  $\mf{b} = \begin{bmatrix*}[r]2\\2\end{bmatrix*}$\vspace{0.2cm}

$\bullet$ $\mf{a} = \begin{bmatrix*}[r]-1\\2\end{bmatrix*}$;  $\mf{b} = \begin{bmatrix*}[r]6\\3\end{bmatrix*}$\vspace{0.2cm}

$\bullet$ $\mf{a} = \begin{bmatrix*}[r]1\\2\\1\end{bmatrix*}$;  $\mf{b} = \begin{bmatrix*}[r]-2\\-4\\-2\end{bmatrix*}$\vspace{0.2cm}
\end{small}
}

\end{column}
\end{columns}
\end{frame}


\begin{frame}[t]{Orthogonal Projection onto Subspaces}
\vspace{-0.2cm}
\begin{small}
\begin{itemize}
    \item We can also project vectors onto other subspaces, which is the generalization of the projection to a 1 dimensional subspace, i.e. the line.
    \item Consider a vector $\mf{b} \in\mb{R}^n$ and a subspace $\mc{S} \subseteq \mb{R}^n$ spanned by the orthonormal basis $\left\{\mf{u}_1, \mf{u}_2, \ldots \mf{u}_r\right\}$.\\
    $\mf{b}_{\mc{S}}$ -- the orthogonal projection of $\mf{b}$ onto $\mc{S}$ is given by the following,
    \[ \mf{b}_{\mc{S}} = \mf{UU}^T\mf{b}; \,\,\, \mf{U} = \begin{bmatrix}\mf{u}_1 & \mf{u}_2 & \ldots & \mf{u}_r \end{bmatrix} \]
    \[ \text{Projection matrix } \mf{P}_{\mc{S}} = \mf{UU}^T \]
    \item A projection matrix is \textbf{idempotent}, i.e. $\mf{P}^2 = \mf{P}$. What does this mean in terms of projecting a vector on to a subspace?
\end{itemize}

\demoex{2}{
Find the orthogonal projection matrix associated $\mc{U} = \left\{\begin{bmatrix*}[r]-1\\-1\\1\end{bmatrix*}, \begin{bmatrix*}[r]2\\1\\3\end{bmatrix*}\right\}$, and find the projection of $\mf{b} = \begin{bmatrix*}[r]2\\2\\3\end{bmatrix*}$ on to $span \lp \mc{U}\rp$.
}
\end{small}
\end{frame}


\begin{frame}[t]{Orthogonal Projection onto Subspaces}

\begin{itemize}
    \item Consider two matrices $\mf{U}_1, \mf{U}_2$ whose columns form an  orthonormal basis of the subspace $\mc{S} \subseteq \mb{R}^m $, $\mc{C}\lp\mf{U}_1\rp = \mc{C}\lp\mf{U}_2\rp$.

    \item The projection matrix onto the subspace $\mc{S}$, $\mf{U}_1\mf{U}_1^T = \mf{U}_2\mf{U}_2^T$. We get the same projection matrix irrespective of which orthonormal basis one uses.
\end{itemize}
\demoex{2}{
    Let $\mf{U}_1 = \bmx1 & 0\\0 & 1\\0 & 0\emx$ and $\mf{U}_1 = \frac{1}{\sqrt{2}}\bmx1 & 1\\1 & -1\\0 & 0\emx$. Find the corresponding projection matrices.
}
\end{frame}

\begin{frame}[t]{Orthogonal Projection onto Subspaces}

\begin{itemize}
    \item Two subspaces $\mc{V}, \mc{W} \subseteq \mc{V}$ are said to be \textbf{complementary subspaces} of $\mc{V}$, when
    \[ \mc{X} + \mc{Y} = \mc{V} \quad \text{and} \quad \mc{X}\cap\mc{Y} = \mf{0} \] 

    \item When two subspaces $\mc{V}, \mc{W} \subseteq \mb{R}^m$ are complementary, then any vector $\mf{x} \in \mb{R}^m$ can be uniquely represented as $\mf{x} = \mf{v} + \mf{w}$, where $\mf{v} \in \mc{V}$ and   $\mf{w} \in \mc{W}$ and $\mf{v}, \mf{w}$ are the components of $\mf{x}$ in $\mc{V}$ and $\mc{W}$ respectively.

    \item When $\mc{V} \perp \mc{W}$, then $\mf{v}^T\mf{w} = 0$; $\mf{v}, \mf{w}$ are orthogonal components. 

    \item If $\mf{P}_\mc{S}$ is the orthogonal projection matrix onto $\mc{S}$, then what is the projection matrix onto $\mc{S}^\perp$?
\end{itemize}
\demoex{2}{
    Let $\mf{u} = \bmx 1 & 1 \emx^T$. Find out the projection matrices $\mf{P}_\mf{u}$ and $\mf{P}_{\mf{u}^\perp}$? Verify that $\mf{P}_{\mf{u}^\perp} = \frac{\mf{u}^\perp\lp{\mf{u}^\perp}\rp^T}{\lp{\mf{u}^\perp}\rp^T\mf{u}^\perp}$.
}
\end{frame}


\begin{frame}[t]{Orthogonal Projection onto Subspaces}
\vspace{-0.2cm}
\begin{itemize}
    \item An orthogonal projection matrix $\mf{P}_\mc{S}$ onto a subspace $\mc{S}$ represents a linear mapping, $\mf{P}_\mc{S}: \mb{R}^m \to \mb{R}^m$. What are the four fundamental subspaces of $\mf{P}_\mc{S}$?\\
    \begin{center}
        \anim{1}{blue}{$\mc{C}\lp \mf{P}_\mc{S}\rp =$}
        \anim{2}{blue}{$\mc{S}; \,\,\, \mc{N}\lp \mf{P}_\mc{S}\rp =$}
        \anim{3}{blue}{$\mc{S}^\perp$\\\vspace{0.2cm} $\mc{N}\lp \mf{P}_\mc{S}^T\rp = \mc{S}^\perp; \,\,\, \mc{C}\lp \mf{P}_\mc{S}^T\rp = \mc{S}$}
    \end{center}
\end{itemize}
\demoex{4}{
    Let $\mf{U} = \bmx \frac{1}{\sqrt{3}} & \frac{1}{\sqrt{6}}\\ \frac{1}{\sqrt{3}} & \frac{1}{\sqrt{6}}\\ \frac{1}{\sqrt{3}} & \frac{-2}{\sqrt{6}} \emx$. Find the orthogonal projection matrix $\mf{P}_{\mf{U}}$ onto $\mc{C}\lp\mf{U}\rp$. Describe the four fundamental subspaces of $\mf{P}_{\mf{U}}$.
}
\vspace{0.3cm}

\demoex{5}{
    Now find $\mf{P}_{\mf{U}^\perp}$ and describe its four fundamental subspaces.
}
\end{frame}

\begin{frame}[t]{Gram-Schmidt Orthogonalization}
\vspace{-0.25cm}
\begin{itemize}
    \item Given a linearly independent set of vectors $\mc{B} = \left\{\mf{x}_1, \mf{x}_2, \ldots \mf{x}_n\right\}$, where $\mf{x}_i \in \mb{R}^m, \,\,\, \forall i \in \left\{1, 2, \ldots n\right\}$, how can we find a orthonormal basis $\left\{\mf{u}_1, \mf{u}_2, \ldots \mf{u}_n\right\}$ for $span\lp \mc{B}\rp $? $\longrightarrow$ \textbf{Gram-Schmidt Algorithm}
    \item Its an iterative procedure that can also detect if a given set $\mc{B}$ is linearly dependent.
\end{itemize}
\begin{small}
\begin{center}
\fbox{\begin{minipage}{35em}
\begin{algorithm}[H]
  \KwData{$\left\{\mf{x}_i\right\}_{i=1}^n$}
  \KwResult{Return an orthonormal basis $\left\{\mf{u}_i\right\}_{i=1}^{n}$ if the set $\mc{B}$ is linearly independent, else return nothing.}
  \For{$i = 1, 2, \ldots n$}{
  1. $\tilde{\mf{q}}_i = \mf{x}_i - \sum_{j=1}^{i-1}\lp \mf{u}_j^T\mf{x}_i\rp \mf{u}_i$ $\longrightarrow$(\textbf{Orthogonalization step})\;
  2. \textbf{If} $\tilde{\mf{q}}_i=0$ \textbf{then} \textbf{return}\;
  3. $\mf{u}_i = \tilde{\mf{q}}_i / \left\Vert\tilde{\mf{q}}_i\right\Vert $ $\longrightarrow$(\textbf{Normalization step})\;
  }
  \textbf{return} $\left\{\mf{u}_i\right\}_{i=1}^n$\;
\end{algorithm}
\end{minipage}}
\end{center}
\end{small}
\end{frame}


\begin{frame}[t]{Gram-Schmidt Orthogonalization}
\vspace{-0.25cm}
\begin{itemize}
    \item The algorithm can also be conveniently represented in a matrix form.
    \[ \mc{B} = \left\{\mf{a}_1, \mf{a}_2, \ldots \mf{a}_n\right\} \]
    \[ \text{Let } \mf{U}_1 = 0_{m \times 1}\,\,\,\text{ and }\,\,\,\mf{U}_i = \begin{bmatrix*}[r]\mf{u}_1 & \mf{u}_2 & \ldots & \mf{u}_{i-1}\end{bmatrix*} \in \mb{R}^{m \times (i - 1)}
    \]
    \[ \mf{U}_i^T\mf{x}_i = \begin{bmatrix*}[c]\mf{u}_1^T\mf{x}_i\\\mf{u}_2^T\mf{x}_i\\\vdots\\\mf{u}_{i-1}^T\mf{x}_i\\\end{bmatrix*}\,\,\,\text{ and }\,\,\, \mf{U}_i\mf{U}_i^T\mf{x}_i = \sum_{j=1}^{i-1}\lp \mf{u}_j^T\mf{x}_i\rp \mf{u}_j
    \]
    \[ \mf{u}_i = \frac{\lp \mf{I} - \mf{U}_i\mf{U}_i^T\rp \mf{x}_i}{\left\lVert \lp \mf{I} - \mf{U}_i\mf{U}_i^T\rp \mf{x}_i\right\rVert} \]
\end{itemize}
\end{frame}

\begin{frame}[t]{$\mf{QR}$ Decomposition}
\vspace{-0.25cm}
\begin{footnotesize}
\begin{itemize}
    \item Gram-Schmidt procedure leads us to another form of matrix  decomposition -- \textbf{QR decomposition}.
    \item Given a matrix $\mf{A} = \begin{bmatrix*}\mf{a}_1&\mf{a}_2&\ldots&\mf{a}_n\end{bmatrix*} \in \mb{R}^{n \times n}$, whose columns form a linearly independent set.\\
    Gramm-Schmidt algorithm produces a orthonormal basis $\left\{\mf{q}_1, \mf{q}_2, \ldots \mf{q}_n\right\}$ for $\mc{C}\lp \mf{A}\rp $.
    \[ \mf{q}_1 = \frac{\mf{a}_1}{r_1}\,\,\,\text{ and }\,\,\, \mf{q}_i = \frac{\mf{a}_i - \sum_{j=1}^{i-1}(\mf{q}_j^T\mf{a}_i)\mf{q}_j}{r_k} \]
    where, $r_1 = \left\lVert \mf{a}_1\right\rVert$ and $r_k = \left\lVert \mf{a}_i - \sum_{j=1}^{i-1}(\mf{q}_j^T\mf{a}_i)\mf{q}_j\right\rVert$.
    \[ \mf{a}_1 = r_1\mf{q}_1\,\,\,\text{ and }\,\,\,\mf{a}_i = r_i\mf{q}_i + \sum_{j=1}^{i-1}\lp \mf{q}_j^T\mf{a}_i\rp \mf{q}_j\]
    \[ \mf{A} = \begin{bmatrix*}\mf{a}_1 & \mf{a}_2 \ldots & \mf{a}_n\end{bmatrix*} =  \begin{bmatrix*}\mf{q}_1 & \mf{q}_2 \ldots & \mf{q}_n\end{bmatrix*}
    \begin{bmatrix*}
    r_1 & \mf{q}_1^T\mf{a}_2 & \mf{q}_1^T\mf{a}_3 & \ldots & \mf{q}_1^T\mf{a}_n\\
    0 & r_2 & \mf{q}_2^T\mf{a}_3 & \ldots & \mf{q}_2^T\mf{a}_n\\
    0 & 0 & r_2 & \ldots & \mf{q}_3^T\mf{a}_n\\
    \vdots & \vdots & \vdots & \ddots & \vdots\\
    0 & 0 & 0 & \ldots & r_n\\\end{bmatrix*} = \mf{QR} \]
\end{itemize}
\end{footnotesize}
\end{frame}


\begin{frame}{$\mf{QR}$ Decomposition}

\begin{color}{black!60}
Find the $\mf{QR}$ factorization for the following, if possible.
$$\mf{A} = \begin{bmatrix*}[r]
-1 & 2 & 1\\
 0 & 0 & 2\\
-4 & 1 & 3\\
\end{bmatrix*}$$

$$\mf{B} = \begin{bmatrix*}[r]
1 & 2 & -1 & -7 \\
1 & 2 & 0 & -5 \\
-4 & 1 & 0 & -16 \\
1 & 1 & 1 & 1 \\
\end{bmatrix*}$$

$$\mf{C} = \begin{bmatrix*}[r]
0 & 2 & -1 \\
1 & 3 & -1 \\
-1 & 1 & 0 \\
1 & 1 & 1 \\
2 & 1 & 0 \\
\end{bmatrix*}$$
\end{color}

\end{frame}


\begin{frame}[t]{$\mf{QR}$ Decomposition}
$$\mf{A} = \mf{QR}; \,\,\, \mf{A}, \mf{Q} \in \mb{R}^{m \times n},\,\, \mf{R} \in \mb{R}^{n \times n}$$
\begin{itemize}
    \item The columns of $\mf{Q}$ form an orthonormal basis for $\mc{C}\lp \mf{A}\rp$, and $\mf{R}$ is upper-triangular.
    \item Similar to $\mf{A} = \mf{LU}$, $\mf{A} = \mf{QR}$ can be used for used to solve $\mf{Ax} = \mf{b}$.
    \[ \mf{Ax} = \mf{QRx} = \mf{b} \implies \mf{Rx} = \mf{Q}^{-1}\mf{b} = \mf{Q}^T\mf{b} \]
\end{itemize}

\demoex{2}{
Solve the following through $\mf{LU}$ and $\mf{QR}$ factorization. 
$$\mf{Ax} = \begin{bmatrix*}[r]
-1 & 2 & 1\\
 0 & 0 & 2\\
-4 & 1 & 3\\
\end{bmatrix*}\begin{bmatrix*}[r]
x_1\\
x_2\\
x_3\\
\end{bmatrix*} = \begin{bmatrix*}[r]
-1\\
-2\\
-2\\
\end{bmatrix*} = \mf{b}$$
}
\end{frame}


\end{document}